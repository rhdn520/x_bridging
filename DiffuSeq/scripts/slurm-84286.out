['diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/ema_0.9999_050000.pt', 'diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/ema_0.9999_040000.pt']
W1015 10:40:15.625000 152232 site-packages/torch/distributed/run.py:774] 
W1015 10:40:15.625000 152232 site-packages/torch/distributed/run.py:774] *****************************************
W1015 10:40:15.625000 152232 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1015 10:40:15.625000 152232 site-packages/torch/distributed/run.py:774] *****************************************
Logging to /tmp/openai-2025-10-15-10-40-24-022675
diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/training_args.json
Namespace(model_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/ema_0.9999_050000.pt', step=2000, out_dir='generation_outputs', top_p=-1, lr=0.0001, batch_size=50, microbatch=64, learning_steps=50000, log_interval=20, save_interval=10000, eval_interval=1000, ema_rate='0.9999', resume_checkpoint='/home/seungwoochoi/data/x_bridging/DiffuSeq/diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251007-22:09:08/ema_0.9999_030000.pt', schedule_sampler='lossaware', diffusion_steps=2000, noise_schedule='sqrt', timestep_respacing='', vocab='bert', use_plm_init='no', vocab_size=30522, config_name='bert-base-uncased', notes='test-qqp20251008-22:34:08', data_dir='/home/seungwoochoi/data/x_bridging/DiffuSeq/datasets/qqp', dataset='qqp', checkpoint_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08', seq_len=128, hidden_t_dim=128, hidden_dim=128, dropout=0.1, use_fp16=False, fp16_scale_growth=0.001, seed=102, gradient_clipping=-1.0, weight_decay=0.0, learn_sigma=False, use_kl=False, predict_xstart=True, rescale_timesteps=True, rescale_learned_sigmas=False, sigma_small=False, emb_scale_factor=1.0, split='valid', clamp_step=0, seed2=123, clip_denoised=False)
### Creating model and diffusion...
Logging to /tmp/openai-2025-10-15-10-40-24-025922
diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/training_args.json
Namespace(model_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/ema_0.9999_050000.pt', step=2000, out_dir='generation_outputs', top_p=-1, lr=0.0001, batch_size=50, microbatch=64, learning_steps=50000, log_interval=20, save_interval=10000, eval_interval=1000, ema_rate='0.9999', resume_checkpoint='/home/seungwoochoi/data/x_bridging/DiffuSeq/diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251007-22:09:08/ema_0.9999_030000.pt', schedule_sampler='lossaware', diffusion_steps=2000, noise_schedule='sqrt', timestep_respacing='', vocab='bert', use_plm_init='no', vocab_size=30522, config_name='bert-base-uncased', notes='test-qqp20251008-22:34:08', data_dir='/home/seungwoochoi/data/x_bridging/DiffuSeq/datasets/qqp', dataset='qqp', checkpoint_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08', seq_len=128, hidden_t_dim=128, hidden_dim=128, dropout=0.1, use_fp16=False, fp16_scale_growth=0.001, seed=102, gradient_clipping=-1.0, weight_decay=0.0, learn_sigma=False, use_kl=False, predict_xstart=True, rescale_timesteps=True, rescale_learned_sigmas=False, sigma_small=False, emb_scale_factor=1.0, split='valid', clamp_step=0, seed2=123, clip_denoised=False)
### Creating model and diffusion...
### The parameter count is 91225274
### The parameter count is 91225274
### Sampling...on valid
args:::
Namespace(model_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/ema_0.9999_050000.pt', step=2000, out_dir='generation_outputs', top_p=-1, lr=0.0001, batch_size=50, microbatch=64, learning_steps=50000, log_interval=20, save_interval=10000, eval_interval=1000, ema_rate='0.9999', resume_checkpoint='/home/seungwoochoi/data/x_bridging/DiffuSeq/diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251007-22:09:08/ema_0.9999_030000.pt', schedule_sampler='lossaware', diffusion_steps=2000, noise_schedule='sqrt', timestep_respacing='', vocab='bert', use_plm_init='no', vocab_size=30522, config_name='bert-base-uncased', notes='test-qqp20251008-22:34:08', data_dir='/home/seungwoochoi/data/x_bridging/DiffuSeq/datasets/qqp', dataset='qqp', checkpoint_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08', seq_len=128, hidden_t_dim=128, hidden_dim=128, dropout=0.1, use_fp16=False, fp16_scale_growth=0.001, seed=102, gradient_clipping=-1.0, weight_decay=0.0, learn_sigma=False, use_kl=False, predict_xstart=True, rescale_timesteps=True, rescale_learned_sigmas=False, sigma_small=False, emb_scale_factor=1.0, split='valid', clamp_step=0, seed2=123, clip_denoised=False)
############################## 
Loading text data...
############################## 
Loading dataset qqp from /home/seungwoochoi/data/x_bridging/DiffuSeq/datasets/qqp...
### Loading form the VALID set...
### Data samples...
 ['Why does he want to have sex with me not her?', 'When/how did you realize were not straight?'] ['Why did he chose me to have sex with?', 'When/how did you realize you were gay/bisexual? Were you in denial?']
RAM used: 1592.28 MB
Dataset({
    features: ['src', 'trg'],
    num_rows: 2048
})
RAM used: 1594.89 MB
### Sampling...on valid
args:::
Namespace(model_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08/ema_0.9999_050000.pt', step=2000, out_dir='generation_outputs', top_p=-1, lr=0.0001, batch_size=50, microbatch=64, learning_steps=50000, log_interval=20, save_interval=10000, eval_interval=1000, ema_rate='0.9999', resume_checkpoint='/home/seungwoochoi/data/x_bridging/DiffuSeq/diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251007-22:09:08/ema_0.9999_030000.pt', schedule_sampler='lossaware', diffusion_steps=2000, noise_schedule='sqrt', timestep_respacing='', vocab='bert', use_plm_init='no', vocab_size=30522, config_name='bert-base-uncased', notes='test-qqp20251008-22:34:08', data_dir='/home/seungwoochoi/data/x_bridging/DiffuSeq/datasets/qqp', dataset='qqp', checkpoint_path='diffusion_models/diffuseq_qqp_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20251008-22:34:08', seq_len=128, hidden_t_dim=128, hidden_dim=128, dropout=0.1, use_fp16=False, fp16_scale_growth=0.001, seed=102, gradient_clipping=-1.0, weight_decay=0.0, learn_sigma=False, use_kl=False, predict_xstart=True, rescale_timesteps=True, rescale_learned_sigmas=False, sigma_small=False, emb_scale_factor=1.0, split='valid', clamp_step=0, seed2=123, clip_denoised=False)
############################## 
Loading text data...
############################## 
Loading dataset qqp from /home/seungwoochoi/data/x_bridging/DiffuSeq/datasets/qqp...
### Loading form the VALID set...
### Data samples...
 ['Why does he want to have sex with me not her?', 'When/how did you realize were not straight?'] ['Why did he chose me to have sex with?', 'When/how did you realize you were gay/bisexual? Were you in denial?']
RAM used: 1593.25 MB
Dataset({
    features: ['src', 'trg'],
    num_rows: 2048
})
RAM used: 1595.84 MB
Running tokenizer on dataset (num_proc=1):   0%|          | 0/2048 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=1):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1000/2048 [00:00<00:00, 3173.90 examples/s]Running tokenizer on dataset (num_proc=1):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2000/2048 [00:00<00:00, 4347.41 examples/s]Running tokenizer on dataset (num_proc=1):   0%|          | 0/2048 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 2899.06 examples/s]
### tokenized_datasets Dataset({
    features: ['input_id_x', 'input_id_y'],
    num_rows: 2048
})
### tokenized_datasets...example [101, 2339, 2515, 2002, 2215, 2000, 2031, 3348, 2007, 2033, 2025, 2014, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
RAM used: 1598.71 MB
merge and mask (num_proc=1):   0%|          | 0/2048 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=1):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1000/2048 [00:00<00:00, 2831.61 examples/s]merge and mask (num_proc=1):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1000/2048 [00:00<00:00, 5092.62 examples/s]Running tokenizer on dataset (num_proc=1):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2000/2048 [00:00<00:00, 3791.09 examples/s]merge and mask (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 4125.58 examples/s]
RAM used: 1603.66 MB
padding (num_proc=1):   0%|          | 0/2048 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 2452.74 examples/s]
### tokenized_datasets Dataset({
    features: ['input_id_x', 'input_id_y'],
    num_rows: 2048
})
### tokenized_datasets...example [101, 2339, 2515, 2002, 2215, 2000, 2031, 3348, 2007, 2033, 2025, 2014, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
RAM used: 1599.79 MB
_collate_batch_helper
merge and mask (num_proc=1):   0%|          | 0/2048 [00:00<?, ? examples/s]
0it [00:00, ?it/s][A1000it [00:00, 563145.01it/s]
_collate_batch_helper

0it [00:00, ?it/s][A1000it [00:00, 889377.44it/s]
_collate_batch_helper
padding (num_proc=1):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1000/2048 [00:00<00:00, 3870.28 examples/s]
0it [00:00, ?it/s][A1000it [00:00, 582057.17it/s]
_collate_batch_helper

0it [00:00, ?it/s][A1000it [00:00, 869466.00it/s]
_collate_batch_helper

0it [00:00, ?it/s][A48it [00:00, 469292.76it/s]
_collate_batch_helper

0it [00:00, ?it/s][A48it [00:00, 666644.34it/s]
padding (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 6199.09 examples/s]merge and mask (num_proc=1):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1000/2048 [00:00<00:00, 4339.91 examples/s]padding (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 3055.32 examples/s]
Dataset({
    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],
    num_rows: 2048
}) padded dataset
Column([[101, 2339, 2515, 2002, 2215, 2000, 2031, 3348, 2007, 2033, 2025, 2014, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1013, 2129, 2106, 2017, 5382, 2020, 2025, 3442, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2073, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 3899, 8902, 2140, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2054, 2079, 2017, 2228, 1996, 3013, 7245, 1997, 24888, 7685, 2355, 7842, 2052, 2022, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2339, 2003, 5522, 2061, 2502, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
Column([[101, 2339, 2106, 2002, 4900, 2033, 2000, 2031, 3348, 2007, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1013, 2129, 2106, 2017, 5382, 2017, 2020, 5637, 1013, 22437, 1029, 2020, 2017, 1999, 14920, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 9127, 2005, 2115, 3899, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2054, 2079, 2017, 2228, 2055, 1996, 24888, 7685, 2355, 3259, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2339, 2038, 5522, 4961, 2000, 2022, 1037, 2107, 2312, 2103, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
Column([[101, 2339, 2515, 2002, 2215, 2000, 2031, 3348, 2007, 2033, 2025, 2014, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2339, 2106, 2002, 4900, 2033, 2000, 2031, 3348, 2007, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1013, 2129, 2106, 2017, 5382, 2020, 2025, 3442, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2043, 1013, 2129, 2106, 2017, 5382, 2017, 2020, 5637, 1013, 22437, 1029, 2020, 2017, 1999, 14920, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2073, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 3899, 8902, 2140, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 9127, 2005, 2115, 3899, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2054, 2079, 2017, 2228, 1996, 3013, 7245, 1997, 24888, 7685, 2355, 7842, 2052, 2022, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2054, 2079, 2017, 2228, 2055, 1996, 24888, 7685, 2355, 3259, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2339, 2003, 5522, 2061, 2502, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2339, 2038, 5522, 4961, 2000, 2022, 1037, 2107, 2312, 2103, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
RAM used: 1610.55 MB
RAM used: 1609.37 MB
merge and mask (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 3577.08 examples/s]
RAM used: 1604.74 MB
data_valid:::
<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8864e11c10>
_collate_batch_helper
padding (num_proc=1):   0%|          | 0/2048 [00:00<?, ? examples/s]
0it [00:00, ?it/s][A1000it [00:00, 555610.54it/s]
_collate_batch_helper

0it [00:00, ?it/s][A1000it [00:00, 854063.12it/s]
_collate_batch_helper
padding (num_proc=1):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1000/2048 [00:00<00:00, 3635.56 examples/s]
0it [00:00, ?it/s][A1000it [00:00, 565956.55it/s]
_collate_batch_helper

0it [00:00, ?it/s][A1000it [00:00, 858081.83it/s]
_collate_batch_helper

0it [00:00, ?it/s][A48it [00:00, 510981.20it/s]
_collate_batch_helper

0it [00:00, ?it/s][A48it [00:00, 627185.64it/s]
### End of reading iteration...
[{'input_ids': tensor([[ 101, 2129, 2172,  ...,    0,    0,    0],
        [ 101, 2129, 2079,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        ...,
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2339, 2003,  ...,    0,    0,    0],
        [ 101, 2339, 4259,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2129, 2323,  ...,    0,    0,    0],
        [ 101, 2054, 2097,  ...,    0,    0,    0],
        [ 101, 2339, 3475,  ...,    0,    0,    0],
        ...,
        [ 101, 2003, 3087,  ...,    0,    0,    0],
        [ 101, 2323, 2111,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 1045, 2439,  ...,    0,    0,    0],
        [ 101, 2129, 2064,  ...,    0,    0,    0],
        ...,
        [ 101, 2129, 2064,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2054, 2020,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2003, 2009,  ...,    0,    0,    0],
        [ 101, 2339, 2079,  ...,    0,    0,    0],
        ...,
        [ 101, 2052, 6221,  ...,    0,    0,    0],
        [ 101, 2129, 2172,  ...,    0,    0,    0],
        [ 101, 2129, 2097,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2339, 2079,  ...,    0,    0,    0],
        [ 101, 1999, 2029,  ...,    0,    0,    0],
        [ 101, 2129, 2515,  ...,    0,    0,    0],
        ...,
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2339, 2003,  ...,    0,    0,    0],
        [ 101, 2129, 2079,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  101,  2071, 15941,  ...,     0,     0,     0],
        [  101,  2054,  2323,  ...,     0,     0,     0],
        [  101,  2054,  2024,  ...,     0,     0,     0],
        ...,
        [  101,  2003, 28625,  ...,     0,     0,     0],
        [  101,  2054,  2079,  ...,     0,     0,     0],
        [  101,  2129,  2079,  ...,     0,     0,     0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2054, 2024,  ...,    0,    0,    0],
        [ 101, 2003, 2051,  ...,    0,    0,    0],
        [ 101, 7897, 1996,  ...,    0,    0,    0],
        ...,
        [ 101, 2339, 2003,  ...,    0,    0,    0],
        [ 101, 2054, 2323,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2054, 2024,  ...,    0,    0,    0],
        [ 101, 2064, 1037,  ...,    0,    0,    0],
        [ 101, 2054, 2097,  ...,    0,    0,    0],
        ...,
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2129, 2003,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2054, 5761,  ...,    0,    0,    0],
        [ 101, 2129, 2003,  ...,    0,    0,    0],
        [ 101, 2054, 2024,  ...,    0,    0,    0],
        ...,
        [ 101, 2054, 2024,  ...,    0,    0,    0],
        [ 101, 2054, 2024,  ...,    0,    0,    0],
        [ 101, 2024, 7486,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2129, 2064,  ...,    0,    0,    0],
        [ 101, 2040, 2003,  ...,    0,    0,    0],
        [ 101, 2029, 2024,  ...,    0,    0,    0],
        ...,
        [ 101, 2079, 2017,  ...,    0,    0,    0],
        [ 101, 2040, 2003,  ...,    0,    0,    0],
        [ 101, 1045, 2081,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {}]
Ïó¨Í∏∞ÏóêÏöî! Ïó¨Í∏∞!
tensor([[ 101, 2129, 2172,  ...,    0,    0,    0],
        [ 101, 2129, 2079,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        ...,
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2339, 2003,  ...,    0,    0,    0],
        [ 101, 2339, 4259,  ...,    0,    0,    0]], device='cuda:1')
noise.shape:::
torch.Size([50, 128, 128])
input_ids_mask.shape:::
torch.Size([50, 128, 128])
tensor([[[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        ...,

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:1')
x_noised:::
padding (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 5951.52 examples/s]padding (num_proc=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2048/2048 [00:00<00:00, 2974.83 examples/s]
Dataset({
    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],
    num_rows: 2048
}) padded dataset
Column([[101, 2339, 2515, 2002, 2215, 2000, 2031, 3348, 2007, 2033, 2025, 2014, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1013, 2129, 2106, 2017, 5382, 2020, 2025, 3442, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2073, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 3899, 8902, 2140, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2054, 2079, 2017, 2228, 1996, 3013, 7245, 1997, 24888, 7685, 2355, 7842, 2052, 2022, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2339, 2003, 5522, 2061, 2502, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
Column([[101, 2339, 2106, 2002, 4900, 2033, 2000, 2031, 3348, 2007, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1013, 2129, 2106, 2017, 5382, 2017, 2020, 5637, 1013, 22437, 1029, 2020, 2017, 1999, 14920, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 9127, 2005, 2115, 3899, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2054, 2079, 2017, 2228, 2055, 1996, 24888, 7685, 2355, 3259, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2339, 2038, 5522, 4961, 2000, 2022, 1037, 2107, 2312, 2103, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
Column([[101, 2339, 2515, 2002, 2215, 2000, 2031, 3348, 2007, 2033, 2025, 2014, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2339, 2106, 2002, 4900, 2033, 2000, 2031, 3348, 2007, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1013, 2129, 2106, 2017, 5382, 2020, 2025, 3442, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2043, 1013, 2129, 2106, 2017, 5382, 2017, 2020, 5637, 1013, 22437, 1029, 2020, 2017, 1999, 14920, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2073, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 3899, 8902, 2140, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2064, 2017, 2131, 1037, 8040, 9541, 3762, 20160, 9127, 2005, 2115, 3899, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2054, 2079, 2017, 2228, 1996, 3013, 7245, 1997, 24888, 7685, 2355, 7842, 2052, 2022, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2054, 2079, 2017, 2228, 2055, 1996, 24888, 7685, 2355, 3259, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2339, 2003, 5522, 2061, 2502, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 101, 2339, 2038, 5522, 4961, 2000, 2022, 1037, 2107, 2312, 2103, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
RAM used: 1619.85 MB
RAM used: 1618.66 MB
tensor([[[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 5.1903e-01,  1.0880e-03,  2.5497e-01,  ...,  2.1951e+00,
           6.4706e-01,  6.4904e-01],
         [ 2.0818e-02,  3.5321e-01, -4.0919e-01,  ...,  5.0326e-01,
          -1.3431e-01,  2.0569e-01],
         ...,
         [ 3.5589e-01, -1.3660e+00,  1.8572e+00,  ...,  1.7579e+00,
           6.5243e-01, -1.4788e+00],
         [ 5.4115e-01, -1.1653e+00, -8.3904e-01,  ..., -1.5669e+00,
           2.0717e-01, -5.1858e-01],
         [ 8.4188e-01,  7.8582e-01,  8.0233e-01,  ..., -9.5586e-01,
           2.3626e+00, -4.1755e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 5.1903e-01,  1.0880e-03,  2.5497e-01,  ...,  2.1951e+00,
           6.4706e-01,  6.4904e-01],
         [-4.8120e-01,  3.2859e-01,  7.6436e-01,  ...,  1.1203e+00,
          -6.6607e-02, -1.8590e+00],
         ...,
         [-1.1760e+00, -6.2517e-02, -2.5419e+00,  ..., -3.6862e-01,
          -8.2452e-01,  1.4624e+00],
         [ 6.8034e-01, -7.9728e-01,  8.5272e-01,  ..., -1.6357e+00,
          -1.0173e+00,  1.3783e+00],
         [-5.1706e-01,  5.1637e-01, -1.8198e-01,  ...,  3.0672e-01,
          -9.0701e-01, -1.6829e+00]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 2.1945e+00, -1.5871e+00, -1.1780e+00,  ..., -1.9555e+00,
           1.2878e+00,  9.9245e-01],
         [ 9.2028e-01,  1.7669e-02,  4.5993e-01,  ..., -2.8118e-01,
          -4.7923e-01, -2.8532e-01],
         ...,
         [-7.3839e-01,  1.0997e+00,  6.3221e-01,  ...,  6.4648e-01,
          -5.6745e-01, -2.9077e-01],
         [-2.4259e-01,  7.9197e-01,  1.0178e+00,  ..., -2.0402e+00,
           8.8743e-01, -3.4466e-01],
         [-3.1968e-01,  1.3496e+00,  1.3669e+00,  ...,  1.0972e+00,
          -5.2564e-02, -5.1871e-01]],

        ...,

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 2.1945e+00, -1.5871e+00, -1.1780e+00,  ..., -1.9555e+00,
           1.2878e+00,  9.9245e-01],
         [ 9.2028e-01,  1.7669e-02,  4.5993e-01,  ..., -2.8118e-01,
          -4.7923e-01, -2.8532e-01],
         ...,
         [-6.1950e-01,  1.7949e-01, -1.9142e-01,  ..., -1.1316e+00,
          -2.8690e-01, -9.3177e-01],
         [ 7.6218e-01,  1.5779e+00, -1.3715e+00,  ...,  4.0585e-01,
          -2.2015e-01, -1.0537e+00],
         [-8.0959e-01, -1.0951e+00,  9.8514e-01,  ...,  3.0036e-01,
           1.1357e-01, -1.9528e+00]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.9580e-01, -1.9276e-02, -1.0321e+00,  ...,  4.5110e-01,
           3.2036e-01,  6.5051e-01],
         [ 9.2028e-01,  1.7669e-02,  4.5993e-01,  ..., -2.8118e-01,
          -4.7923e-01, -2.8532e-01],
         ...,
         [ 8.0226e-01, -1.5699e+00, -5.1032e-01,  ..., -1.0311e+00,
          -6.2939e-01, -3.5822e-01],
         [ 6.3693e-01,  3.3776e-01, -1.0707e-01,  ..., -8.2956e-01,
          -5.3334e-01, -5.4286e-02],
         [-3.7083e-01, -1.1469e+00, -3.8533e-01,  ...,  1.4833e+00,
           2.6762e-01, -2.1574e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.9580e-01, -1.9276e-02, -1.0321e+00,  ...,  4.5110e-01,
           3.2036e-01,  6.5051e-01],
         [-7.3565e-01, -1.8703e-01,  4.3175e-01,  ..., -2.8470e-01,
           1.9592e-01, -1.2775e-01],
         ...,
         [-1.8950e+00,  3.9954e-01,  2.7176e-01,  ..., -7.9452e-01,
           4.6339e-01, -8.3949e-02],
         [-7.4319e-01,  3.5048e-01, -1.6131e+00,  ..., -3.1265e-01,
          -7.8162e-01,  1.3521e+00],
         [ 1.4846e+00, -1.7172e-01, -6.8668e-01,  ..., -3.5887e-02,
           2.4899e-01, -1.7042e+00]]], device='cuda:1')
data_valid:::
<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f7874837950>
tensor([[[ 1.3391e+00,  2.0517e-01, -1.6879e+00,  ...,  3.0034e-01,
           2.4361e-01,  1.3300e+00],
         [-2.1876e+00,  1.2062e+00,  2.4879e+00,  ..., -1.6132e+00,
           4.7601e-01,  2.5014e-03],
         [-1.7649e+00, -8.6785e-01,  3.7906e-01,  ...,  2.0008e-01,
          -6.4239e-01, -7.2586e-01],
         ...,
         [ 3.5589e-01, -1.3660e+00,  1.8572e+00,  ...,  1.7579e+00,
           6.5243e-01, -1.4788e+00],
         [ 5.4115e-01, -1.1653e+00, -8.3904e-01,  ..., -1.5669e+00,
           2.0717e-01, -5.1858e-01],
         [ 8.4188e-01,  7.8582e-01,  8.0233e-01,  ..., -9.5586e-01,
           2.3626e+00, -4.1755e-01]],

        [[-1.0006e-02, -1.9970e+00,  1.4241e+00,  ..., -2.9553e-01,
           2.6520e-01,  9.8374e-01],
         [ 3.5454e-01,  1.1005e+00, -6.2468e-01,  ..., -4.6070e-01,
          -4.1340e-02, -2.4805e+00],
         [-1.1545e+00, -9.1427e-01, -7.4817e-01,  ...,  7.4983e-01,
           9.1281e-01, -9.5906e-01],
         ...,
         [-1.1760e+00, -6.2517e-02, -2.5419e+00,  ..., -3.6862e-01,
          -8.2452e-01,  1.4624e+00],
         [ 6.8034e-01, -7.9728e-01,  8.5272e-01,  ..., -1.6357e+00,
          -1.0173e+00,  1.3783e+00],
         [-5.1706e-01,  5.1637e-01, -1.8198e-01,  ...,  3.0672e-01,
          -9.0701e-01, -1.6829e+00]],

        [[-3.7527e-01,  1.7520e+00,  1.4753e+00,  ...,  4.8711e-01,
          -1.2070e+00, -1.7252e+00],
         [ 1.3080e+00,  1.1190e+00, -1.6056e-01,  ..., -1.7120e+00,
          -1.8138e-01,  1.1597e+00],
         [ 9.4131e-01, -4.3354e-01, -8.0529e-02,  ...,  3.0656e-01,
           4.0213e-01,  3.7210e-01],
         ...,
         [-7.3839e-01,  1.0997e+00,  6.3221e-01,  ...,  6.4648e-01,
          -5.6745e-01, -2.9077e-01],
         [-2.4259e-01,  7.9197e-01,  1.0178e+00,  ..., -2.0402e+00,
           8.8743e-01, -3.4466e-01],
         [-3.1968e-01,  1.3496e+00,  1.3669e+00,  ...,  1.0972e+00,
          -5.2564e-02, -5.1871e-01]],

        ...,

        [[ 4.6356e-01,  1.6236e+00, -3.3629e-01,  ...,  4.2238e-01,
           3.5100e-01,  1.6238e-01],
         [-4.4103e-01, -1.8612e+00,  4.7498e-01,  ...,  4.1981e-01,
          -9.4678e-01, -4.4487e-01],
         [-6.0670e-01, -4.3255e-01,  1.4004e+00,  ..., -3.8307e-01,
          -5.7291e-02, -1.1139e+00],
         ...,
         [-6.1950e-01,  1.7949e-01, -1.9142e-01,  ..., -1.1316e+00,
          -2.8690e-01, -9.3177e-01],
         [ 7.6218e-01,  1.5779e+00, -1.3715e+00,  ...,  4.0585e-01,
          -2.2015e-01, -1.0537e+00],
         [-8.0959e-01, -1.0951e+00,  9.8514e-01,  ...,  3.0036e-01,
           1.1357e-01, -1.9528e+00]],

        [[ 6.8672e-01,  4.9236e-01, -4.3892e-01,  ...,  1.0962e+00,
          -6.0276e-01, -2.5300e-01],
         [-1.1076e+00,  1.0564e+00, -2.7319e-01,  ...,  1.7688e+00,
           8.6049e-01,  5.8575e-01],
         [-6.8721e-01, -9.9341e-01,  5.6410e-01,  ..., -2.0665e+00,
          -8.7943e-01, -2.0620e-01],
         ...,
         [ 8.0226e-01, -1.5699e+00, -5.1032e-01,  ..., -1.0311e+00,
          -6.2939e-01, -3.5822e-01],
         [ 6.3693e-01,  3.3776e-01, -1.0707e-01,  ..., -8.2956e-01,
          -5.3334e-01, -5.4286e-02],
         [-3.7083e-01, -1.1469e+00, -3.8533e-01,  ...,  1.4833e+00,
           2.6762e-01, -2.1574e-01]],

        [[-1.5178e+00, -7.3215e-02,  8.5789e-01,  ...,  1.3239e+00,
          -4.9077e-01,  6.5641e-01],
         [-7.5972e-01,  1.2984e+00, -5.9627e-01,  ..., -1.3904e-01,
           4.7636e-01, -2.7074e-01],
         [-5.8533e-01,  1.5385e+00,  1.5530e+00,  ...,  3.9679e-01,
          -8.0493e-01, -1.6953e+00],
         ...,
         [-1.8950e+00,  3.9954e-01,  2.7176e-01,  ..., -7.9452e-01,
           4.6339e-01, -8.3949e-02],
         [-7.4319e-01,  3.5048e-01, -1.6131e+00,  ..., -3.1265e-01,
          -7.8162e-01,  1.3521e+00],
         [ 1.4846e+00, -1.7172e-01, -6.8668e-01,  ..., -3.5887e-02,
           2.4899e-01, -1.7042e+00]]], device='cuda:1')
### End of reading iteration...
[{'input_ids': tensor([[ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2129, 2097,  ...,    0,    0,    0],
        [ 101, 2339, 5796,  ...,    0,    0,    0],
        ...,
        [ 101, 2339, 2079,  ...,    0,    0,    0],
        [ 101, 2054, 2323,  ...,    0,    0,    0],
        [ 101, 2040, 2079,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2129, 2515,  ...,    0,    0,    0],
        [ 101, 2129, 2515,  ...,    0,    0,    0],
        [ 101, 2054, 2168,  ...,    0,    0,    0],
        ...,
        [ 101, 2339, 2079,  ...,    0,    0,    0],
        [ 101, 2097, 1996,  ...,    0,    0,    0],
        [ 101, 2339, 2106,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2129, 2064,  ...,    0,    0,    0],
        [ 101, 2129, 2064,  ...,    0,    0,    0],
        [ 101, 2129, 2064,  ...,    0,    0,    0],
        ...,
        [ 101, 2129, 2079,  ...,    0,    0,    0],
        [ 101, 2073, 2064,  ...,    0,    0,    0],
        [ 101, 2515, 2166,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2129, 2079,  ...,    0,    0,    0],
        [ 101, 2054, 2024,  ...,    0,    0,    0],
        [ 101, 2129, 2064,  ...,    0,    0,    0],
        ...,
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2054, 4813,  ...,    0,    0,    0],
        [ 101, 2129, 2079,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  101,  2054,  2003,  ...,     0,     0,     0],
        [  101,  2040, 12778,  ...,     0,     0,     0],
        [  101,  2079,  2070,  ...,     0,     0,     0],
        ...,
        [  101,  2054,  2024,  ...,     0,     0,     0],
        [  101,  2054,  2003,  ...,     0,     0,     0],
        [  101,  2129,  2064,  ...,     0,     0,     0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 4205, 1040,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        ...,
        [ 101, 2129, 2064,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2064, 3765,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  101,  2129,  2064,  ...,     0,     0,     0],
        [  101, 14670,  1997,  ...,     0,     0,     0],
        [  101,  2129,  2079,  ...,     0,     0,     0],
        ...,
        [  101,  2097,  3607,  ...,     0,     0,     0],
        [  101,  2029,  2003,  ...,     0,     0,     0],
        [  101,  2339,  2106,  ...,     0,     0,     0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2054, 2024,  ...,    0,    0,    0],
        [ 101, 2129, 2003,  ...,    0,    0,    0],
        [ 101, 2054, 2024,  ...,    0,    0,    0],
        ...,
        [ 101, 2029, 7997,  ...,    0,    0,    0],
        [ 101, 2079, 2796,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2029, 2024,  ...,    0,    0,    0],
        [ 101, 2054, 2024,  ...,    0,    0,    0],
        [ 101, 2024, 2529,  ...,    0,    0,    0],
        ...,
        [ 101, 2515, 7344,  ...,    0,    0,    0],
        [ 101, 2054, 2001,  ...,    0,    0,    0],
        [ 101, 2129, 2079,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2129, 2097,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0],
        ...,
        [ 101, 2060, 2084,  ...,    0,    0,    0],
        [ 101, 2129, 2079,  ...,    0,    0,    0],
        [ 101, 2054, 6433,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 101, 2129, 2515,  ...,    0,    0,    0],
        [ 101, 2339, 2079,  ...,    0,    0,    0],
        [ 101, 2003, 2009,  ...,    0,    0,    0],
        ...,
        [ 101, 2129, 2079,  ...,    0,    0,    0],
        [ 101, 2129, 2064,  ...,    0,    0,    0],
        [ 101, 2054, 3303,  ...,    0,    0,    0]]), 'input_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1]])}]
Ïó¨Í∏∞ÏóêÏöî! Ïó¨Í∏∞!
tensor([[ 101, 2054, 2003,  ...,    0,    0,    0],
        [ 101, 2129, 2097,  ...,    0,    0,    0],
        [ 101, 2339, 5796,  ...,    0,    0,    0],
        ...,
        [ 101, 2339, 2079,  ...,    0,    0,    0],
        [ 101, 2054, 2323,  ...,    0,    0,    0],
        [ 101, 2040, 2079,  ...,    0,    0,    0]], device='cuda:0')
noise.shape:::
torch.Size([50, 128, 128])
input_ids_mask.shape:::
torch.Size([50, 128, 128])
tensor([[[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        ...,

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0')
x_noised:::
tensor([[[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 2.1945e+00, -1.5871e+00, -1.1780e+00,  ..., -1.9555e+00,
           1.2878e+00,  9.9245e-01],
         [ 9.2028e-01,  1.7669e-02,  4.5993e-01,  ..., -2.8118e-01,
          -4.7923e-01, -2.8532e-01],
         ...,
         [ 3.5589e-01, -1.3660e+00,  1.8572e+00,  ...,  1.7579e+00,
           6.5243e-01, -1.4788e+00],
         [ 5.4115e-01, -1.1653e+00, -8.3904e-01,  ..., -1.5669e+00,
           2.0717e-01, -5.1858e-01],
         [ 8.4188e-01,  7.8582e-01,  8.0233e-01,  ..., -9.5586e-01,
           2.3626e+00, -4.1755e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 5.1903e-01,  1.0880e-03,  2.5497e-01,  ...,  2.1951e+00,
           6.4706e-01,  6.4904e-01],
         [-1.0386e+00,  2.3537e-01, -5.9821e-01,  ..., -5.1919e-01,
          -3.0595e-01, -2.9330e-02],
         ...,
         [-1.1760e+00, -6.2517e-02, -2.5419e+00,  ..., -3.6862e-01,
          -8.2452e-01,  1.4624e+00],
         [ 6.8034e-01, -7.9728e-01,  8.5272e-01,  ..., -1.6357e+00,
          -1.0173e+00,  1.3783e+00],
         [-5.1706e-01,  5.1637e-01, -1.8198e-01,  ...,  3.0672e-01,
          -9.0701e-01, -1.6829e+00]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.9580e-01, -1.9276e-02, -1.0321e+00,  ...,  4.5110e-01,
           3.2036e-01,  6.5051e-01],
         [ 1.1348e+00, -4.1379e-02,  4.2574e-01,  ...,  1.4861e-01,
           2.8947e-01,  6.2414e-01],
         ...,
         [-7.3839e-01,  1.0997e+00,  6.3221e-01,  ...,  6.4648e-01,
          -5.6745e-01, -2.9077e-01],
         [-2.4259e-01,  7.9197e-01,  1.0178e+00,  ..., -2.0402e+00,
           8.8743e-01, -3.4466e-01],
         [-3.1968e-01,  1.3496e+00,  1.3669e+00,  ...,  1.0972e+00,
          -5.2564e-02, -5.1871e-01]],

        ...,

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.9580e-01, -1.9276e-02, -1.0321e+00,  ...,  4.5110e-01,
           3.2036e-01,  6.5051e-01],
         [-4.8120e-01,  3.2859e-01,  7.6436e-01,  ...,  1.1203e+00,
          -6.6607e-02, -1.8590e+00],
         ...,
         [-6.1950e-01,  1.7949e-01, -1.9142e-01,  ..., -1.1316e+00,
          -2.8690e-01, -9.3177e-01],
         [ 7.6218e-01,  1.5779e+00, -1.3715e+00,  ...,  4.0585e-01,
          -2.2015e-01, -1.0537e+00],
         [-8.0959e-01, -1.0951e+00,  9.8514e-01,  ...,  3.0036e-01,
           1.1357e-01, -1.9528e+00]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 2.1945e+00, -1.5871e+00, -1.1780e+00,  ..., -1.9555e+00,
           1.2878e+00,  9.9245e-01],
         [ 4.1600e-02,  3.2687e-01,  3.6519e-01,  ...,  2.3684e-01,
          -1.0691e+00, -2.4088e-01],
         ...,
         [ 8.0226e-01, -1.5699e+00, -5.1032e-01,  ..., -1.0311e+00,
          -6.2939e-01, -3.5822e-01],
         [ 6.3693e-01,  3.3776e-01, -1.0707e-01,  ..., -8.2956e-01,
          -5.3334e-01, -5.4286e-02],
         [-3.7083e-01, -1.1469e+00, -3.8533e-01,  ...,  1.4833e+00,
           2.6762e-01, -2.1574e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.1764e+00, -6.7407e-01,  5.8128e-01,  ...,  6.1248e-01,
          -5.0665e-01,  6.5662e-01],
         [-4.8120e-01,  3.2859e-01,  7.6436e-01,  ...,  1.1203e+00,
          -6.6607e-02, -1.8590e+00],
         ...,
         [-1.8950e+00,  3.9954e-01,  2.7176e-01,  ..., -7.9452e-01,
           4.6339e-01, -8.3949e-02],
         [-7.4319e-01,  3.5048e-01, -1.6131e+00,  ..., -3.1265e-01,
          -7.8162e-01,  1.3521e+00],
         [ 1.4846e+00, -1.7172e-01, -6.8668e-01,  ..., -3.5887e-02,
           2.4899e-01, -1.7042e+00]]], device='cuda:0')
tensor([[[ 1.3391e+00,  2.0517e-01, -1.6879e+00,  ...,  3.0034e-01,
           2.4361e-01,  1.3300e+00],
         [-2.1876e+00,  1.2062e+00,  2.4879e+00,  ..., -1.6132e+00,
           4.7601e-01,  2.5014e-03],
         [-1.7649e+00, -8.6785e-01,  3.7906e-01,  ...,  2.0008e-01,
          -6.4239e-01, -7.2586e-01],
         ...,
         [ 3.5589e-01, -1.3660e+00,  1.8572e+00,  ...,  1.7579e+00,
           6.5243e-01, -1.4788e+00],
         [ 5.4115e-01, -1.1653e+00, -8.3904e-01,  ..., -1.5669e+00,
           2.0717e-01, -5.1858e-01],
         [ 8.4188e-01,  7.8582e-01,  8.0233e-01,  ..., -9.5586e-01,
           2.3626e+00, -4.1755e-01]],

        [[-1.0006e-02, -1.9970e+00,  1.4241e+00,  ..., -2.9553e-01,
           2.6520e-01,  9.8374e-01],
         [ 3.5454e-01,  1.1005e+00, -6.2468e-01,  ..., -4.6070e-01,
          -4.1340e-02, -2.4805e+00],
         [-1.1545e+00, -9.1427e-01, -7.4817e-01,  ...,  7.4983e-01,
           9.1281e-01, -9.5906e-01],
         ...,
         [-1.1760e+00, -6.2517e-02, -2.5419e+00,  ..., -3.6862e-01,
          -8.2452e-01,  1.4624e+00],
         [ 6.8034e-01, -7.9728e-01,  8.5272e-01,  ..., -1.6357e+00,
          -1.0173e+00,  1.3783e+00],
         [-5.1706e-01,  5.1637e-01, -1.8198e-01,  ...,  3.0672e-01,
          -9.0701e-01, -1.6829e+00]],

        [[-3.7527e-01,  1.7520e+00,  1.4753e+00,  ...,  4.8711e-01,
          -1.2070e+00, -1.7252e+00],
         [ 1.3080e+00,  1.1190e+00, -1.6056e-01,  ..., -1.7120e+00,
          -1.8138e-01,  1.1597e+00],
         [ 9.4131e-01, -4.3354e-01, -8.0529e-02,  ...,  3.0656e-01,
           4.0213e-01,  3.7210e-01],
         ...,
         [-7.3839e-01,  1.0997e+00,  6.3221e-01,  ...,  6.4648e-01,
          -5.6745e-01, -2.9077e-01],
         [-2.4259e-01,  7.9197e-01,  1.0178e+00,  ..., -2.0402e+00,
           8.8743e-01, -3.4466e-01],
         [-3.1968e-01,  1.3496e+00,  1.3669e+00,  ...,  1.0972e+00,
          -5.2564e-02, -5.1871e-01]],

        ...,

        [[ 4.6356e-01,  1.6236e+00, -3.3629e-01,  ...,  4.2238e-01,
           3.5100e-01,  1.6238e-01],
         [-4.4103e-01, -1.8612e+00,  4.7498e-01,  ...,  4.1981e-01,
          -9.4678e-01, -4.4487e-01],
         [-6.0670e-01, -4.3255e-01,  1.4004e+00,  ..., -3.8307e-01,
          -5.7291e-02, -1.1139e+00],
         ...,
         [-6.1950e-01,  1.7949e-01, -1.9142e-01,  ..., -1.1316e+00,
          -2.8690e-01, -9.3177e-01],
         [ 7.6218e-01,  1.5779e+00, -1.3715e+00,  ...,  4.0585e-01,
          -2.2015e-01, -1.0537e+00],
         [-8.0959e-01, -1.0951e+00,  9.8514e-01,  ...,  3.0036e-01,
           1.1357e-01, -1.9528e+00]],

        [[ 6.8672e-01,  4.9236e-01, -4.3892e-01,  ...,  1.0962e+00,
          -6.0276e-01, -2.5300e-01],
         [-1.1076e+00,  1.0564e+00, -2.7319e-01,  ...,  1.7688e+00,
           8.6049e-01,  5.8575e-01],
         [-6.8721e-01, -9.9341e-01,  5.6410e-01,  ..., -2.0665e+00,
          -8.7943e-01, -2.0620e-01],
         ...,
         [ 8.0226e-01, -1.5699e+00, -5.1032e-01,  ..., -1.0311e+00,
          -6.2939e-01, -3.5822e-01],
         [ 6.3693e-01,  3.3776e-01, -1.0707e-01,  ..., -8.2956e-01,
          -5.3334e-01, -5.4286e-02],
         [-3.7083e-01, -1.1469e+00, -3.8533e-01,  ...,  1.4833e+00,
           2.6762e-01, -2.1574e-01]],

        [[-1.5178e+00, -7.3215e-02,  8.5789e-01,  ...,  1.3239e+00,
          -4.9077e-01,  6.5641e-01],
         [-7.5972e-01,  1.2984e+00, -5.9627e-01,  ..., -1.3904e-01,
           4.7636e-01, -2.7074e-01],
         [-5.8533e-01,  1.5385e+00,  1.5530e+00,  ...,  3.9679e-01,
          -8.0493e-01, -1.6953e+00],
         ...,
         [-1.8950e+00,  3.9954e-01,  2.7176e-01,  ..., -7.9452e-01,
           4.6339e-01, -8.3949e-02],
         [-7.4319e-01,  3.5048e-01, -1.6131e+00,  ..., -3.1265e-01,
          -7.8162e-01,  1.3521e+00],
         [ 1.4846e+00, -1.7172e-01, -6.8668e-01,  ..., -3.5887e-02,
           2.4899e-01, -1.7042e+00]]], device='cuda:0')
torch.Size([50, 128, 128])
torch.Size([50, 128, 30522])
WWWW
torch.Size([50, 128, 1])
torch.Size([50, 128])
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(104)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
  0%|          | 0/11 [00:00<?, ?it/s]/data3/seungwoochoi/.conda/envs/diffu_seq/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1015 10:44:11.001575754 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
torch.Size([50, 128, 128])
torch.Size([50, 128, 30522])
WWWW
torch.Size([50, 128, 1])
torch.Size([50, 128])
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(104)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(104)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(83)
torch.Size([128])
tensor(87)
torch.Size([128])
tensor(87)
/data3/seungwoochoi/.conda/envs/diffu_seq/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1015 10:44:12.171862339 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Ïó¨Í∏∞ÏóêÏöî! Ïó¨Í∏∞!
Ïó¨Í∏∞ÏóêÏöî! Ïó¨Í∏∞!
tensor([[ 101, 2129, 2323,  ...,    0,    0,    0],
        [ 101, 2054, 2097,  ...,    0,    0,    0],
        [ 101, 2339, 3475,  ...,    0,    0,    0],
        ...,
        [ 101, 2003, 3087,  ...,    0,    0,    0],
        [ 101, 2323, 2111,  ...,    0,    0,    0],
        [ 101, 2054, 2003,  ...,    0,    0,    0]], device='cuda:1')
noise.shape:::
torch.Size([50, 128, 128])
tensor([[ 101, 2129, 2515,  ...,    0,    0,    0],
        [ 101, 2129, 2515,  ...,    0,    0,    0],
        [ 101, 2054, 2168,  ...,    0,    0,    0],
        ...,
        [ 101, 2339, 2079,  ...,    0,    0,    0],
        [ 101, 2097, 1996,  ...,    0,    0,    0],
        [ 101, 2339, 2106,  ...,    0,    0,    0]], device='cuda:0')
noise.shape:::
torch.Size([50, 128, 128])
input_ids_mask.shape:::
torch.Size([50, 128, 128])
input_ids_mask.shape:::
torch.Size([50, 128, 128])
tensor([[[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        ...,

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:1')
x_noised:::
tensor([[[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        ...,

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1],
         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0')
x_noised:::
tensor([[[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 5.1903e-01,  1.0880e-03,  2.5497e-01,  ...,  2.1951e+00,
           6.4706e-01,  6.4904e-01],
         [ 4.1600e-02,  3.2687e-01,  3.6519e-01,  ...,  2.3684e-01,
          -1.0691e+00, -2.4088e-01],
         ...,
         [-5.7649e-01, -1.0957e+00,  1.2471e+00,  ..., -2.9971e-01,
           4.8147e-01, -1.5185e+00],
         [-5.8593e-01, -1.8932e+00, -3.6520e-01,  ..., -1.6234e-01,
          -1.4524e+00,  3.0076e-01],
         [ 1.9746e-01, -2.3838e+00,  5.1563e-02,  ..., -1.9683e-01,
           3.4195e-01,  1.1621e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 2.1945e+00, -1.5871e+00, -1.1780e+00,  ..., -1.9555e+00,
           1.2878e+00,  9.9245e-01],
         [-1.0386e+00,  2.3537e-01, -5.9821e-01,  ..., -5.1919e-01,
          -3.0595e-01, -2.9330e-02],
         ...,
         [-2.2066e-01, -6.7576e-01, -1.2189e+00,  ...,  2.9858e-01,
          -9.4234e-01, -1.0467e+00],
         [-3.0739e-01, -5.8460e-01, -4.1149e-01,  ..., -2.1361e+00,
           6.0800e-01, -1.4163e+00],
         [ 3.8448e-01, -6.1428e-01,  1.1245e+00,  ...,  9.1651e-02,
          -9.8137e-01, -3.1935e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.9580e-01, -1.9276e-02, -1.0321e+00,  ...,  4.5110e-01,
           3.2036e-01,  6.5051e-01],
         [-4.3665e-01, -2.5476e-01, -1.3131e+00,  ..., -5.8106e-03,
          -1.2089e-01, -2.9681e-01],
         ...,
         [-4.5276e-01, -9.5666e-01, -7.2182e-01,  ..., -5.5294e-01,
           1.1611e+00,  1.6061e+00],
         [-1.2113e+00,  8.6560e-01, -6.8068e-01,  ..., -1.3956e+00,
          -1.0037e+00,  4.3782e-01],
         [-8.4354e-01, -1.0125e+00, -1.3077e+00,  ...,  8.5916e-01,
           1.1419e+00,  8.0801e-01]],

        ...,

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 9.2028e-01,  1.7669e-02,  4.5993e-01,  ..., -2.8118e-01,
          -4.7923e-01, -2.8532e-01],
         [ 1.1606e-01, -8.2520e-01, -4.2331e-02,  ..., -2.7687e-01,
           1.3486e-03,  1.5464e-01],
         ...,
         [-1.2485e-01,  5.9335e-01,  2.2980e+00,  ..., -1.1176e+00,
           1.1634e+00, -4.8216e-01],
         [-1.3409e-01,  2.4116e-01,  8.7104e-01,  ...,  3.1317e-01,
           7.1719e-02,  1.4613e-01],
         [ 5.9004e-01,  9.1267e-01, -5.4833e-01,  ..., -7.9816e-01,
          -1.2989e+00, -1.4404e+00]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 4.1600e-02,  3.2687e-01,  3.6519e-01,  ...,  2.3684e-01,
          -1.0691e+00, -2.4088e-01],
         [ 1.1693e+00,  3.4841e-01, -1.1685e-01,  ...,  8.1865e-01,
          -8.9452e-02,  1.2122e-01],
         ...,
         [ 4.8116e-02,  1.1201e+00,  3.3374e-01,  ..., -1.4390e+00,
          -1.5517e+00,  8.4643e-02],
         [-3.4277e-01,  2.3848e-01, -8.8916e-01,  ..., -6.2060e-01,
           2.8797e-01, -9.2176e-01],
         [-7.8253e-01, -4.4390e-01, -1.2398e+00,  ..., -2.7336e+00,
           1.6380e-01, -1.8632e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 2.1945e+00, -1.5871e+00, -1.1780e+00,  ..., -1.9555e+00,
           1.2878e+00,  9.9245e-01],
         [ 9.2028e-01,  1.7669e-02,  4.5993e-01,  ..., -2.8118e-01,
          -4.7923e-01, -2.8532e-01],
         ...,
         [ 2.7628e-01,  1.8657e-01,  4.6397e-01,  ..., -4.5291e-01,
           3.5301e-01, -3.9453e-01],
         [-8.9163e-01,  3.2300e-01, -4.5077e-01,  ...,  2.5247e-01,
           2.1401e+00,  3.2050e-01],
         [-6.9122e-01,  9.8992e-01, -2.3090e+00,  ..., -7.5937e-02,
           1.4529e+00, -1.0740e+00]]], device='cuda:1')
tensor([[[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 5.1903e-01,  1.0880e-03,  2.5497e-01,  ...,  2.1951e+00,
           6.4706e-01,  6.4904e-01],
         [ 4.2236e-01,  8.9042e-01, -2.3180e-01,  ..., -7.6674e-02,
          -1.0336e+00,  6.2186e-01],
         ...,
         [-5.7649e-01, -1.0957e+00,  1.2471e+00,  ..., -2.9971e-01,
           4.8147e-01, -1.5185e+00],
         [-5.8593e-01, -1.8932e+00, -3.6520e-01,  ..., -1.6234e-01,
          -1.4524e+00,  3.0076e-01],
         [ 1.9746e-01, -2.3838e+00,  5.1563e-02,  ..., -1.9683e-01,
           3.4195e-01,  1.1621e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 5.1903e-01,  1.0880e-03,  2.5497e-01,  ...,  2.1951e+00,
           6.4706e-01,  6.4904e-01],
         [ 4.2236e-01,  8.9042e-01, -2.3180e-01,  ..., -7.6674e-02,
          -1.0336e+00,  6.2186e-01],
         ...,
         [-2.2066e-01, -6.7576e-01, -1.2189e+00,  ...,  2.9858e-01,
          -9.4234e-01, -1.0467e+00],
         [-3.0739e-01, -5.8460e-01, -4.1149e-01,  ..., -2.1361e+00,
           6.0800e-01, -1.4163e+00],
         [ 3.8448e-01, -6.1428e-01,  1.1245e+00,  ...,  9.1651e-02,
          -9.8137e-01, -3.1935e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 2.1945e+00, -1.5871e+00, -1.1780e+00,  ..., -1.9555e+00,
           1.2878e+00,  9.9245e-01],
         [ 1.7152e-02,  4.2295e-01,  2.1999e-01,  ...,  5.6222e-02,
           1.1143e-01, -1.4032e-01],
         ...,
         [-4.5276e-01, -9.5666e-01, -7.2182e-01,  ..., -5.5294e-01,
           1.1611e+00,  1.6061e+00],
         [-1.2113e+00,  8.6560e-01, -6.8068e-01,  ..., -1.3956e+00,
          -1.0037e+00,  4.3782e-01],
         [-8.4354e-01, -1.0125e+00, -1.3077e+00,  ...,  8.5916e-01,
           1.1419e+00,  8.0801e-01]],

        ...,

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.9580e-01, -1.9276e-02, -1.0321e+00,  ...,  4.5110e-01,
           3.2036e-01,  6.5051e-01],
         [-4.8120e-01,  3.2859e-01,  7.6436e-01,  ...,  1.1203e+00,
          -6.6607e-02, -1.8590e+00],
         ...,
         [-1.2485e-01,  5.9335e-01,  2.2980e+00,  ..., -1.1176e+00,
           1.1634e+00, -4.8216e-01],
         [-1.3409e-01,  2.4116e-01,  8.7104e-01,  ...,  3.1317e-01,
           7.1719e-02,  1.4613e-01],
         [ 5.9004e-01,  9.1267e-01, -5.4833e-01,  ..., -7.9816e-01,
          -1.2989e+00, -1.4404e+00]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [-1.0386e+00,  2.3537e-01, -5.9821e-01,  ..., -5.1919e-01,
          -3.0595e-01, -2.9330e-02],
         [-1.2736e+00,  1.1369e+00, -5.6547e-01,  ..., -1.6979e+00,
           8.3061e-02,  2.4749e-01],
         ...,
         [ 4.8116e-02,  1.1201e+00,  3.3374e-01,  ..., -1.4390e+00,
          -1.5517e+00,  8.4643e-02],
         [-3.4277e-01,  2.3848e-01, -8.8916e-01,  ..., -6.2060e-01,
           2.8797e-01, -9.2176e-01],
         [-7.8253e-01, -4.4390e-01, -1.2398e+00,  ..., -2.7336e+00,
           1.6380e-01, -1.8632e-01]],

        [[ 1.2315e+00,  6.2410e-01,  2.3442e-01,  ...,  3.3925e-01,
           4.6947e-01, -4.5509e-01],
         [ 1.9580e-01, -1.9276e-02, -1.0321e+00,  ...,  4.5110e-01,
           3.2036e-01,  6.5051e-01],
         [-2.1831e-01,  1.3423e-01, -6.2744e-01,  ...,  5.4568e-01,
          -4.8874e-01, -4.5509e-01],
         ...,
         [ 2.7628e-01,  1.8657e-01,  4.6397e-01,  ..., -4.5291e-01,
           3.5301e-01, -3.9453e-01],
         [-8.9163e-01,  3.2300e-01, -4.5077e-01,  ...,  2.5247e-01,
           2.1401e+00,  3.2050e-01],
         [-6.9122e-01,  9.8992e-01, -2.3090e+00,  ..., -7.5937e-02,
           1.4529e+00, -1.0740e+00]]], device='cuda:0')
tensor([[[-1.8423, -0.4141,  0.6452,  ..., -1.2612, -1.3046,  1.0197],
         [-1.5393,  0.9771,  2.5622,  ..., -0.0043,  1.1351, -0.8052],
         [ 0.6881,  0.8554,  0.4180,  ..., -0.6856, -0.0854, -1.2460],
         ...,
         [-0.5765, -1.0957,  1.2471,  ..., -0.2997,  0.4815, -1.5185],
         [-0.5859, -1.8932, -0.3652,  ..., -0.1623, -1.4524,  0.3008],
         [ 0.1975, -2.3838,  0.0516,  ..., -0.1968,  0.3420,  0.1162]],

        [[-0.9593,  0.2587, -0.6457,  ...,  0.2315,  1.3513, -0.2983],
         [ 0.2004,  0.9265, -0.8742,  ...,  0.3011, -0.1786,  1.0493],
         [ 1.2813, -0.9037, -0.3389,  ...,  0.0329, -0.3495, -0.7832],
         ...,
         [-0.2207, -0.6758, -1.2189,  ...,  0.2986, -0.9423, -1.0467],
         [-0.3074, -0.5846, -0.4115,  ..., -2.1361,  0.6080, -1.4163],
         [ 0.3845, -0.6143,  1.1245,  ...,  0.0917, -0.9814, -0.3194]],

        [[-1.8898,  1.2807, -2.0006,  ...,  0.5513, -0.5864, -1.9465],
         [ 0.1495,  0.7816,  0.7742,  ..., -0.7228,  0.6294, -0.4265],
         [-0.5435,  0.7281, -1.0584,  ...,  1.4576, -0.6890, -0.2945],
         ...,
         [-0.4528, -0.9567, -0.7218,  ..., -0.5529,  1.1611,  1.6061],
         [-1.2113,  0.8656, -0.6807,  ..., -1.3956, -1.0037,  0.4378],
         [-0.8435, -1.0125, -1.3077,  ...,  0.8592,  1.1419,  0.8080]],

        ...,

        [[ 0.4358, -0.9245,  0.9454,  ...,  0.8569, -1.2970,  0.7356],
         [-2.0387,  1.2126, -0.0616,  ...,  1.2010,  0.0774, -0.1218],
         [-2.2794,  0.0600,  0.3598,  ..., -0.9698,  0.1775, -0.0848],
         ...,
         [-0.1248,  0.5934,  2.2980,  ..., -1.1176,  1.1634, -0.4822],
         [-0.1341,  0.2412,  0.8710,  ...,  0.3132,  0.0717,  0.1461],
         [ 0.5900,  0.9127, -0.5483,  ..., -0.7982, -1.2989, -1.4404]],

        [[ 0.1646, -1.0142, -0.5944,  ...,  0.8439,  0.0358,  0.3340],
         [-1.2866,  0.8864, -0.2597,  ...,  1.2498,  0.5231, -1.0516],
         [ 0.0530,  0.0416, -0.6079,  ..., -0.9530,  1.8119, -0.1249],
         ...,
         [ 0.0481,  1.1201,  0.3337,  ..., -1.4390, -1.5517,  0.0846],
         [-0.3428,  0.2385, -0.8892,  ..., -0.6206,  0.2880, -0.9218],
         [-0.7825, -0.4439, -1.2398,  ..., -2.7336,  0.1638, -0.1863]],

        [[ 1.6653,  0.3142,  0.1090,  ..., -0.2889,  0.9729, -0.3120],
         [-0.2493,  1.1280, -1.4065,  ..., -0.0636,  1.2602,  0.5473],
         [-1.0746,  0.1735, -0.6136,  ..., -0.2678,  1.6393,  0.1040],
         ...,
         [ 0.2763,  0.1866,  0.4640,  ..., -0.4529,  0.3530, -0.3945],
         [-0.8916,  0.3230, -0.4508,  ...,  0.2525,  2.1401,  0.3205],
         [-0.6912,  0.9899, -2.3090,  ..., -0.0759,  1.4529, -1.0740]]],
       device='cuda:1')
tensor([[[-1.8423, -0.4141,  0.6452,  ..., -1.2612, -1.3046,  1.0197],
         [-1.5393,  0.9771,  2.5622,  ..., -0.0043,  1.1351, -0.8052],
         [ 0.6881,  0.8554,  0.4180,  ..., -0.6856, -0.0854, -1.2460],
         ...,
         [-0.5765, -1.0957,  1.2471,  ..., -0.2997,  0.4815, -1.5185],
         [-0.5859, -1.8932, -0.3652,  ..., -0.1623, -1.4524,  0.3008],
         [ 0.1975, -2.3838,  0.0516,  ..., -0.1968,  0.3420,  0.1162]],

        [[-0.9593,  0.2587, -0.6457,  ...,  0.2315,  1.3513, -0.2983],
         [ 0.2004,  0.9265, -0.8742,  ...,  0.3011, -0.1786,  1.0493],
         [ 1.2813, -0.9037, -0.3389,  ...,  0.0329, -0.3495, -0.7832],
         ...,
         [-0.2207, -0.6758, -1.2189,  ...,  0.2986, -0.9423, -1.0467],
         [-0.3074, -0.5846, -0.4115,  ..., -2.1361,  0.6080, -1.4163],
         [ 0.3845, -0.6143,  1.1245,  ...,  0.0917, -0.9814, -0.3194]],

        [[-1.8898,  1.2807, -2.0006,  ...,  0.5513, -0.5864, -1.9465],
         [ 0.1495,  0.7816,  0.7742,  ..., -0.7228,  0.6294, -0.4265],
         [-0.5435,  0.7281, -1.0584,  ...,  1.4576, -0.6890, -0.2945],
         ...,
         [-0.4528, -0.9567, -0.7218,  ..., -0.5529,  1.1611,  1.6061],
         [-1.2113,  0.8656, -0.6807,  ..., -1.3956, -1.0037,  0.4378],
         [-0.8435, -1.0125, -1.3077,  ...,  0.8592,  1.1419,  0.8080]],

        ...,

        [[ 0.4358, -0.9245,  0.9454,  ...,  0.8569, -1.2970,  0.7356],
         [-2.0387,  1.2126, -0.0616,  ...,  1.2010,  0.0774, -0.1218],
         [-2.2794,  0.0600,  0.3598,  ..., -0.9698,  0.1775, -0.0848],
         ...,
         [-0.1248,  0.5934,  2.2980,  ..., -1.1176,  1.1634, -0.4822],
         [-0.1341,  0.2412,  0.8710,  ...,  0.3132,  0.0717,  0.1461],
         [ 0.5900,  0.9127, -0.5483,  ..., -0.7982, -1.2989, -1.4404]],

        [[ 0.1646, -1.0142, -0.5944,  ...,  0.8439,  0.0358,  0.3340],
         [-1.2866,  0.8864, -0.2597,  ...,  1.2498,  0.5231, -1.0516],
         [ 0.0530,  0.0416, -0.6079,  ..., -0.9530,  1.8119, -0.1249],
         ...,
         [ 0.0481,  1.1201,  0.3337,  ..., -1.4390, -1.5517,  0.0846],
         [-0.3428,  0.2385, -0.8892,  ..., -0.6206,  0.2880, -0.9218],
         [-0.7825, -0.4439, -1.2398,  ..., -2.7336,  0.1638, -0.1863]],

        [[ 1.6653,  0.3142,  0.1090,  ..., -0.2889,  0.9729, -0.3120],
         [-0.2493,  1.1280, -1.4065,  ..., -0.0636,  1.2602,  0.5473],
         [-1.0746,  0.1735, -0.6136,  ..., -0.2678,  1.6393,  0.1040],
         ...,
         [ 0.2763,  0.1866,  0.4640,  ..., -0.4529,  0.3530, -0.3945],
         [-0.8916,  0.3230, -0.4508,  ...,  0.2525,  2.1401,  0.3205],
         [-0.6912,  0.9899, -2.3090,  ..., -0.0759,  1.4529, -1.0740]]],
       device='cuda:0')
srun: got SIGCONT
slurmstepd-n02: error: *** JOB 84286 ON n02 CANCELLED AT 2025-10-15T10:44:19 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: forcing job termination
  9%|‚ñâ         | 1/11 [03:43<37:16, 223.65s/it]slurmstepd-n02: error: *** STEP 84286.0 ON n02 CANCELLED AT 2025-10-15T10:44:19 ***
W1015 10:44:19.132000 152232 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1015 10:44:19.134000 152232 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 152368 closing signal SIGTERM
W1015 10:44:19.135000 152232 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 152369 closing signal SIGTERM
